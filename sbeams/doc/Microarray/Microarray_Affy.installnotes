
Notes installing the SBEAMS - Microarray_Affy module

Background)

ISB developed the microarray module to initially deal with organizing and analyzing 
2-color data from arrays printed in-house.  Starting around July 2004, development started to
extended the Microarray module to organize and analyze the Affymetrix Expression array data.
The install instructions are for setting up just the Affy portion of the module.  You may notice that 
some tables and links are not utilized by the Affy portion of the Microarray module but are still visible 
since both the 2-color and Affy array infrastructure were built out within the same sbeams module.


-------------------------------------------------------------------------------
1) Software and module Dependencies

You must first install the SBEAMS Core.  See the separate installation
notes (sbeams.installnotes) on how to accomplish that. You must also
install the BioLink module; follow the installation instructions
provided with that module first (BioLink.installnotes).


The following Perl Modules often not found on a standard UNIX/Linux
setup are required to successfully use SBEAMS - Microarray_Affy (in addition
to the dependencies for the SBEAMS Core).

XML::LibXML;
Tie::IxHash;
XML::Writer
Archive::Zip
Statistics::R [Optional] Not used in production code.  Only used in a test script Make_R_graph.cgi to demonstrate making a 
	 	graph in using R and Perl
---------------
The following non-Perl software is required:

R -Version 2.0 or greater
R -Bioconductor libraries, see below 
 library(affy)
 library(gcrma)
 library(vsn)

 library(Biobase)
 library(multtest)
 library(annaffy)
 library(webbioc)

 library(siggenes)
 
 #XSLT transformation engine {semi-optional} Only need to view the help pages
 Ehttp://xmlsoft.org/XSLT/
 xsltproc


-------------------------------------------------------------------------------
2) Installation Location

SBEAMS is designed to live entirely in the "htdocs" area of your Apache
web server.  For the remainder of this installation, it will be assumed
that your installation is configured as follows; compensate for your
specific setup:
  servername: db
  DocumentRoot: /local/www/html
  Primary location: directly located in DocumentRoot,
                   /local/www/html/sbeams  --> http://db/sbeams/
  Development location: In a dev1 tree starting in the DocumentRoot,
                   /local/www/html/dev1/sbeams  -> http://db/dev1/sbeams/

All modules live in the same area and should be unpacked into the
main SBEAMS area.



-------------------------------------------------------------------------------
3) Create and populate the database

It is assumed that you have already created and tested your SBEAMS Core
database.  You may either create a separate database for the Microarray_Affy
database or you can put everything in the same database.

Note that some database engines (rare now) may not permit
cross-database queries in which case your may NOT use separate
databases.  If you do use separate databases, you may not be able to
enforce referential integrity between tables in the different
databases.  This may or may not be a significant concern.

- If you decide on a separate database, create it and within it,
  create users "sbeams" and "sbeamsro" as a read/write
  account and a read-only account, respectively, as done for the Core.

- Generate the appropriate schema for your type(s) of database as follows:

setenv SBEAMS /local/html/dev1/sbeams
cd $SBEAMS/lib/scripts/Core

foreach dbtype ( mssql mysql pgsql oracle )
  ./generate_schema.pl \
    --table_prop ../../conf/Microarray/Microarray_table_property.txt \
    --table_col ../../conf/Microarray/Microarray_table_column.txt \
    --schema_file ../../sql/Microarray/Microarray \
    --destination_type $dbtype
end


- Verify that the SQL CREATE and DROP statements have been correctly
  generated in $SBEAMS/lib/sql/Microarray/

- Execute the statements to create and populate the database with some
  bare bones data and indexes (for faster loading and querying):

SQL Server Example:

To CREATE and POPULATE:
sqsh -i $SBEAMS/lib/sql/Microarray/Microarray_CREATETABLES.mssql -D sbeamsdev
sqsh -i $SBEAMS/lib/sql/Microarray/Microarray_POPULATE.mssql -D sbeamsdev
sqsh -i $SBEAMS/lib/sql/Microarray/Microarray_CREATECONSTRAINTS.mssql -D sbeamsdev

To CREATE indexes:
sqsh -i $SBEAMS/lib/sql/Microarray/Microarray_CREATEINDEXES.mssql -D sbeamsdev

To CREATE Manual Constraints (Constraints that could not be auto-generated)
sqsh -i $SBEAMS/lib/sql/Microarray/Microarray_ADD_MANUAL_CONSTRAINTS.mssql

To DROP:
sqsh -i $SBEAMS/lib/sql/Microarray/Microarray_DROPCONSTRAINTS.mssql -D sbeamsdev
sqsh -i $SBEAMS/lib/sql/Microarray/Microarray_DROPTABLES.mssql -D sbeamsdev
sqsh -i $SBEAMS/lib/sql/Microarray/Microarray_DROPINDEXES.sql
sqsh -i $SBEAMS/lib/sql/Microarray/Microarray_DROP_MANUAL_CONSTRAINTS.mssql

Note that the Microarray_POPULATE.mssql is not auto-generated and should
probably work for all flavors of database

Examples for table creation for other database flavors can be found in the
Core installation notes and will not be repeated here.

Notes:
A few warnings or errors might be seen while creating the tables and constraints.  The ones
below should be considered normal
#Table not used by the Affy Portion of the module
Error: Foreign key 'fk_array_request_sample_array_request_slide_id' references invalid table 'dbo.MA_array_request_MA_slide'.
#In order for some of the linking table to display correctly on some of the web forms
#the conf file was altered to know how to do certain things.  As a side affect it produced
# a few incorrect sql statements
Error: Column 'dbo.sample_protocol.sample_protocol_id' is not the same data type as referencing column 'array_request_sample.protocol_ids' in foreign key 'fk_array_request_sample_protocol_ids'.
Error: Column 'dbo.affy_array_sample_protocol.affy_array_sample_protocol_id' is not the same data type as referencing column 'affy_array_sample.affy_sample_protocol_ids' in foreign key 'fk_affy_array_sample_affy_sample_protocol_ids'.
Error: Column 'dbo.affy_array_protocol.affy_array_protocol_id' is not the same data type as referencing column 'affy_array.affy_array_protocol_ids' in foreign key 'fk_affy_array_affy_array_protocol_ids'.
#Sizes does not matter..
W (1): Warning: The table 'file_location' has been created but its maximum row size (8080) exceeds the maximum number of bytes per row (8060). INSERT or UPDATE of a row in this table will fail if the resulting row length exceeds 8060 bytes.

-------------------------------------------------------------------------------
3-1) Data storage locations and naming conventions

ISB Affymetrix Core facility name it's files with the following convention

All Files generated by the core facility CEL, CHP, XML, RPT files all use the common root name
YYYYMMDD_DD_<SAMPLE_NAME>.<ext>
YYYYMMDD = Date array was scanned
DD       = Unique Scan Number per Day ie 01, 02, 03....
Sample_name = User Sample Name, No Spaces or strange characters

Data Location.
All the data is located within one main directory which is subdivided into folders named
YYYYMM - <Year><Month>

For external dataset download we have a folder "external" within the main data repository and individual 
experiments to be loaded are separated into a user defined folder

A cron job can be setup (see below) to keep monitoring the default directory for any new files to be uploaded

For inital setup make the following folders
mkdir $SBEAMS/tmp \
$SBEAMS/tmp/Microarray \
$SBEAMS/tmp/Microarray/AFFY_ANNO_LOGS \
$SBEAMS/tmp/Microarray/GetExpression \
$SBEAMS/tmp/Microarray/GetExpression/jws \
$SBEAMS/var \
$SBEAMS/var/Microarray \
$SBEAMS/var/Microarray/Affy_data \
$SBEAMS/var/Microarray/Affy_data/probe_data \
$SBEAMS/var/Microarray/Affy_data/probe_data/external \
$SBEAMS/var/Microarray/Affy_data/delivery \
$SBEAMS/var/Microarray/Affy_data/annotation

chgrp -R sbeams $SBEAMS/tmp; chgrp -R sbeams $SBEAMS/var
chmod -R g+s $SBEAMS/tmp; chmod -R g+s $SBEAMS/var;

-------------------------------------------------------------------------------
4-1) Edit the SBEAMS Configuration files

setenv SBEAMS /local/www/html/dev1/sbeams

cd $SBEAMS/lib/conf
edit SBEAMS.conf

Specifically:

DBPREFIX{Microarray_Affy}    = microarray.dbo.


4-2) Edit the SBEAMS Microarray/Settings.pm file

cd $SBEAMS/lib/perl/SBEAMS/Microarray
edit Settings.pm

Specifically: use the default folders created above and tweak the perl variables
to look like the lines below

$AFFY_DEFAULT_DIR	    = "$PHYSICAL_BASE_DIR/var/Microarray/Affy_data/probe_data";
$BIOCONDUCTOR_DELIVERY_PATH = "$PHYSICAL_BASE_DIR/var/Microarray/Affy_data/delivery";
$ADD_ANNOTATION_OUT_FOLDER  = "$PHYSICAL_BASE_DIR/tmp/Microarray/Add_affy_annotation";

  Notes: $AFFY_DEFAULT_DIR = Full path to a folder that will house all Affy CEL files
  	 $BIOCONDUCTOR_DELIVERY_PATH = Location that all analysis results will be written to(see below)
	 $ADD_ANNOTATION_OUT_FOLDER  = Location that errors from loading affy annotation files will be kept 
	 			        
  Notes: The web server user will need read access to the CEL file folders and read/write access to the 
	 $BIOCONDUCTOR_DELIVERY_PATH folder



-------------------------------------------------------------------------------
5) Populate the driver tables and register the module

cd $SBEAMS/lib/scripts/Core
set CONFDIR = "../../conf"
./update_driver_tables.pl $CONFDIR/Microarray/Microarray_table_property.txt
./update_driver_tables.pl $CONFDIR/Microarray/Microarray_table_column.txt
./update_driver_tables.pl $CONFDIR/Microarray/Microarray_table_column_manual.txt

If this doesn't work.  Do not proceed, debug first.

-Register the module:
cd $SBEAMS/lib/conf/Core
echo Microarray >> AvailableModules.conf

-------------------------------------------------------------------------------
6) Add groups

Log in via the web interface as a user with Administrator privileges,
switch to the Admin group using the pull-down menu at the top, and add
three work groups:
[SBEAMS Home] [Admin] [Manage Work Groups] [Add Work Group]
Add entries for (exactly as shown!):
  Microarray_user
  Microarray_admin
  Microarray_readonly
(Note that after INSERTing the first, you can click [Back], edit the previous
information slightly, and click [INSERT] to add another.)

Microarray_admin has privilege over all tables in the Microarray
module, while the Microarray_user only has access to certain tables
and may often not modify other users records.  The Microarray_readonly
group is a separate group for looky loos.

Now go to [Manage User Group Associations], [Add ...], and add
yourself and whoever else to these groups as appropriate.

Now set up the table group securities:
  rowprivate - Microarray_user - data_writer
  rowprivate - Microarray_admin - data_writer
  rowprivate - Microarray_readonly - data_writer
  project - Microarray_user - data_writer
  project - Microarray_admin - data_modifier
  arrays - Microarray_user - data_writer
  arrays - Microarray_admin - data_modifier


Now that the Microarray driver tables are loaded, and the groups have been
established, you should be able to go to the web site again and click on
SBEAMS - Microarray and explore the tables.  They're all going to be empty,
but you shouldn't get any errors, just empty resultsets.

If this doesn't work.  Do not proceed, debug first.


-------------------------------------------------------------------------------
7) Add some sample data

########################
Test Data Background
- Set 1) Using  a small subset of data (6 of 158 arrays) File: Human_test_data.tar
- Set 2) 4 arrays on (HG-133 Plus 2). Experiments with C4-2 and LNCaP human prostate cancer cell lines.  File: Affy_test_data.tar.gz
########################
- Download the data setes from
http://www.sbeams.org/sample_data/
Click on the link "Human_test_data.tar.gz"
Click on the link "Affy_test_data.tar.gz"
Save the data to any folder or use the folder below

- Unpack the data and annotation file and copy them to the data folders
cd $SBEAMS/lib/refdata/Microarray
gunzip Human_test_data.tar.gz
tar -xvf Human_test_data.tar

gunzip Affy_test_data.tar.gz
tar -xvf Affy_test_data.tar

 
- Make the folders to hold the CEL files
mkdir $SBEAMS/var/Microarray/Affy_data/probe_data/external/Human_test
mkdir $SBEAMS/var/Microarray/Affy_data/probe_data/200404

- Move the the CEL files And info file to the test folder
mv ./Human_test_data/*.CEL $SBEAMS/var/Microarray/Affy_data/probe_data/external/Human_test/.
mv ./Human_test_data/Master_info_file_test_data.txt $SBEAMS/var/Microarray/Affy_data/probe_data/external/Human_test

-Move All the files CEL, XML, RPT files from the Affy_test_data to the data folder
mv ./20040421_* $SBEAMS/var/Microarray/Affy_data/probe_data/200404/.


-Move the annotation file to annotation directory
mv ./Human_test_data/HG-U133A_annot.csv $SBEAMS/var/Microarray/Affy_data/annotation/.
mv HG-U133_Plus_2_annot.csv $SBEAMS/var/Microarray/Affy_data/annotation/.

########################
(logged in as your user account)

Add a Project as follows:

- Switch to the Microarray_user group by using the drop-down box at top
- Click on [SBEAMS Home]
- Under "My Projects" tab, click [Add A New Project].
  Required fields are in red.  If you don't have a budget number, enter NA.
- Make a project using the following information
   Project Name: "Human Gene Atlas"
   Project Tag:  "GeneAtlas_human"
   Description:  "Human microarray data from novartis research foundation's Gene Atlas project
   http://wombat.gnf.org/"
- Fill in the appropriate information and click [INSERT]

- Make a second Project
- Click the 'Go Back' button 
- Make a project using the following information
   Project Name: "ISB Test Data"
   Project Tag:  "ISB_test"
   Description:  "4 Human CEL files HG-U133_Plus_2.  2 files from Human LN prostate cancer cell, 2files from C4-2 cancer cell lines"
- Fill in the appropriate information and click [INSERT]

########################
Add An Array Type
- Switch to the Microarray_admin group by using the drop-down box at top
- Switch to the the Microarray Module, Click On [Microarray]
- At the bottom of the page, on the Navigation bar click on [Slide Type/Costs] button
- Click On [Add Slide Type]
- Fill in the Data
   Name: "HG-U133A"
   Organism: "Human"
   Comment: "Affymetrix Human U133A"
- Click Insert

- Make a second array 
- Click the 'Go Back' Button
  Name: "HG-U133_Plus_2"
  Organism: "Human"
  Comment: "Affymetrix Human Genome U133 Plus 2.0 Array"
- Click Insert

########################  
Add Analysis Protocol
- Switch to the Microarray_admin group by using the drop-down box at top
- Switch to the the Microarray Module, Click On [Microarray]
- At the bottom of the page, on the Navigation bar click on [Protocols] button
- Click [Add Protocol]
- Add a new Protocol Type, Click the "Plus Icon" next to Protocol Type
- Fill in Protcol Type Name --> "image_analysis", Click Insert.
- Go Back to the Add Protocol Page, and refresh the page.
- Insert the data 
   Protocol Type --> "image_analysis",
   Name          --> "R Mas5.0 CHP",
   Protocols     --> "Use R-bioconductor to turn a CEL file into a CHP file" 
- Click Insert
 ########################  
Add Hyb Protocol
- Switch to the Microarray_admin group by using the drop-down box at top
- Switch to the the Microarray Module, Click On [Microarray]
- Switch to the the Microarray Module, Click On [Microarray]
- At the bottom of the page, on the Navigation bar click on [Protocols] button
- Click [Add Protocol]
- Add a new Protocol Type, Click the "Plus Icon" next to Protocol Type
- Fill in Protcol Type Name --> "hybridization", Click Insert.
- Go Back to the Add Protocol Page, and refresh the page.
- Insert the data 
   Protocol Type --> "hybridization",
   Name          --> "AFFY EukGE-WS2v5_450",
   Protocols     --> "Paste in the text output from the affy wash station" 
- Click Insert
########################
- Click the "Go Back" Button
Add Scanning Protocol
- Insert the data 
   Protocol Type --> "array_scanning",
   Name          --> "AFFY Scanning",
   Protocols     --> "Paste in the text output from the affy scanner" 
 - Click Insert  
########################
- Click the "Go Back" Button
Add Feature extraction Protocol
- Insert the data
   Protocol Type --> "image_analysis",
   Name          --> "AFFY Feature Extraction",
   Protocols     --> "Generation of CEL file from DAT file is automatic in GCOS 1.0+ Software" 
- Click Insert
########################
- Click the "Go Back" Button
Add CHP Generation Protocol
- Insert the data
   Protocol Type --> "image_analysis",
   Name          --> "AFFY GCOS CHP Generation",
   Protocols     --> "Create CHP file in GCOS by right-clicking a CEL file and choosing 'Analyze'"
- Click Insert
########################
Add Server Info
- Some of the scripts and database tables keep track of file paths and the server name needs to be
entered before some of the scripts will work
- Manually construct the URL to enter the data below
- The url should be almost the same for the ones above for adding an array, but the TABLE_NAME will = MA_server
http://<server_name>/sbeams/cgi/Microarray/ManageTable.cgi?TABLE_NAME=MA_server
- Enter the server name
- Click [Insert]


########################
Add the Annotation for this array type

- Annotation are downloaded from Affymetrix on quarterly basis.  This must be done manually.  The file provided in the 
test data set was downloaded from Affymetrix.
- Use the script to upload the annotation into SBEAMS

cd $SBEAMS/lib/scripts/Microarray
./load_affy_annotation_files.pl --run_mode update \
--file_name $SBEAMS/var/Microarray/Affy_data/annotation/HG-U133A_annot.csv

It could take about 10-15 minutes to upload the data...

- Add the annotation for the second array
./load_affy_annotation_files.pl --run_mode update \
--file_name $SBEAMS/var/Microarray/Affy_data/annotation/HG-U133_Plus_2_annot.csv


########################
Add the external arrays to the database

- See sections about naming conventions (3-2)
- The Data in the "Human_test_data.tar.gz" folder contains CEL files that were not generated at ISB, so they did not
have all the support data needed to automaticlly load the arrays from the core facility.

- Adding external arrays is a two step process.
- All the sample annotation is first collected in a "master_info" file which is just a tab
  delimited file.
- This file is then parsed to produce a info_file for each CEL file to be uploaded
- See Below on how to upload data from a MAGE-XML file produced by the Affymetrix GCOS software


- View the template on how to make a master_info file.  [Not needed for this example, the info file already exists]
$SBEAMS/usr/Microarray/Example_master_upload_template.xls

- Run the script to parse the master_info file
cd $SBEAMS/lib/scripts/Microarray
./Pre_process_affy_info_file.pl --run_mode make_new \
--info_file $SBEAMS/var/Microarray/Affy_data/probe_data/external/Human_test/Master_info_file_test_data.txt

- Run the script to upload the data into SBEAMS
- This script will scan the default data directory (set in the Settings file) looking for new data
 cd $SBEAMS/lib/scripts/Microarray
 ./load_affy_array_files.pl --run_mode add_new

########################
Add more data to the database  MAGE-XML data.

- The data contained within the file "Affy_test_data.tar.gz" contains from 4 arrays scanned at ISB.
- In addition to the CEL file is a CHP, RPT and XML files that were produced by the Affymetrix software GCOS.
-  ISB exports the MAGE-XML from the GCOS with one extra attribute that will be need for the current to parse the data.
- Setup GCOS software ## Only needed if trying to import data not from ISB, that extracts data from the MAGE-XML from the GCOS software
	Goto the GCOS Manager, Click on the template tab.  
	Create a new template
	Add New Attribute "Array User Name" Type "String" Required "Yes"
	Make sure to use the template when exporting data from the GCOS software after scannning slides
- 

########################
Add expression data to the database
Convert CEL file to CHP data using R-bioconductor

cd $SBEAMS/lib/scripts/Microarray
./load_affy_R_CHP_files.pl --run_mode add_new
##Note this will take a while of time to process, and running this on a fast machine whould be a good idea

- Test to see if the data has been entered properly
- Open the url
http://<sbeams_server>/sbeams/cgi/Microarray/GetAffy_GeneIntensity.cgi
- Enter "IL%" in the box Gene Name, Click 'Simple Query'

-------------------------------------------------------------------------------
8) Setup the help pages
########################

Setting up the Affy user Help pages
- There is a set of user help pages that were made for the end users and it shows how to use the different pages
- The pages need an XSL processing engine to work.  Curently they are setup to use xsltproc by defualt.

Check to to see if xsltproc is installed
 xsltproc -V
 If it's not installed goto  http://xmlsoft.org/XSLT/ and install the programs
 
- Set the site specific information to locate the files.  Go and edit the following two files.
cd $SBEAMS/doc/Microarray/affy_help_pages/includes

- Edit the file 
vi transformation_info.inc.php
- Change the following variables to point to where the files are installed
Example, Change $SBEAMS to suit your needs
$URL_BASE  = "http://<$SBEAMS>/doc/Microarray/affy_help_pages"
$BASE_PATH = "<$SBEAMS>/doc/Microarray/affy_help_pages"

$HOME_PAGE_URL = "<Local intra-net page>"


- Edit the xslt file to add the correct server name
cd $SBEAMS/doc/Microarray/affy_help_pages/Affy_help
vi Affy_help.xslt

- Change the lines, to indicate your servers that are running both SBEAMS and the affy help pages
<xsl:variable name="Affy_home_server">db.systemsbiology.net</xsl:variable>
<xsl:variable name="Sbeams_server">db.systemsbiology.net</xsl:variable>


To See if the links work check out the page http://<sbeams_server>/doc/Microarray/affy_help_pages/
Most of the links are relative but a few links go directly into SBEAMS therefore the need to set the above links
Also note some of the links will not work since they are specific to ISB

-------------------------------------------------------------------------------
9) Setup the analysis pipeline
########################
Setup the analysis pipeline

The analysis pipeline allows users to analize affy arrays and find differentially expressed genes.  The analysis is done
in R and the processing can be done on the local server or passed off to a batch processor like pbs.  A series of web pages
will walk the users through the analysis pipeline so there is no need for the user to read/write the R code.

The CGI pages were initially written as part of the bioconductor project.  See the bioconductor vignette on "Textual Description of webbioc"
to learn more about the requirements for running and requirements for running these pages (Link below).  It should be noted that you do NOT have to download
the pages from bioconductor, the pages have been total integrated into SBEAMS so the actual use of the pages is a bit different and the analysis
capabilities have been extended, but the setup requirements and some of the settings are still applicable
http://bioconductor.org/repository/devel/vignette/demoscript.pdf

- Setup Variables in Setting.pm
Make sure the setting done in step 4-2 is complete for the variable  $BIOCONDUCTOR_DELIVERY_PATH


After the folder is setup change the permissions to make sure the web user can write to the folder, see below

########### Change directory permissions if data is not local to the web server

At ISB the data produced by these scripts is not kept local to the web server.

So the web user needs permission to write to the remote drives.

Have IT setup a new group affydata

Add the web user to this group.

setup the folder "delivery" and change the group to affydata

Need to set group id on the delivery folder so all data written into the folder 
will have the group arraydata
$SBEAMS/var/Microarray/Affy_data/delivery  chmod g+s


To run the job on pbs you might need to create a new user to run the jobs (See Below for more info)

We create a user arraybot and added it to the affydata group.

Need to setup a key less ssh connection to the pbs server so the apache cgi
script can hand off the job to the batch schedular
(GET MORE DETAIL)
#############


- Setup Variable in Site.pm
cd $SBEAMS/cgi/Microarray/bioconductor
vi Site.pm
#change the variables below to meet the needs of your site.  
#currently they are hard coded to isb variables

$ADMIN_EMAIL
$R_BINARY
$R_LIBS
$AFFY_ANNO_PATH
$JAVA_PATH
#Fist setup a java keystore (See Below)
$KEYSTORE = '<java_keystore_path>'
#PLEASE READ THE VIGNETTE LISTED ABOVE TO MAKE THE DECISION ON WHICH OPTION TO USE FOR BATCH_SYSTEM
# To start it might be best to try 'fork' and the processing will run on the web server.  Please
# note that this could be computationally expensive and slow the server down
$BATCH_SYSTEM 

###############
The keystores and signing jar files is only need if the Cytoscape and MEV programs are utilized
Use the steps below to create one for sbeams and then use the script below to re-sign the jar files since

Setup the a keystore for sbeams.  Example below
keytool -keystore <local_path_on_web_server>/.keystore -genkey -alias sbeamsDev
Enter keystore password: sbeamsDevKey
What is your first and last name?
[Unknown]: SBEAMS Development Team
What is the name of your organizational unit?
[Unknown]: SBEAMS Development
What is the name of your organization?
[Unknown]: Institute for Systems Biology
What is the name of your City or Locality?
[Unknown]: Seattle
What is the name of your State or Province?
[Unknown]: WA
What is the two-letter country code for this unit?
[Unknown]: US
Is CN=SBEAMS Development Team, OU=SBEAMS Development, O=Institute for Systems Biology, L=Seattle, ST=WA, C=US correct?
[no]: yes

Enter key password for <sbeamsDev>
(RETURN if same as keystore password):


Need to update the makefile for signing the data files
cd $SBEAMS/lib/cytoscape/Microarray/GetExpression
vi makefile 
#change the line to match your site.  
#<java_path>                                     <keystore_path>                    <password>       <key to use, see above>    
/tools/java/j2sdk1.4.2/bin/jarsigner -keystore /users/pshannon/.keystore -storepass cytokey data.jar cytoscape

###############


To run the pages
#Open the main Microarray Modual web page
- Click on [Microarray]
- Click on [Data Pipeline] 
- Click on [Affy Analysis Pipeline]
- Click on [Start New Analysis Session]
#Make sure there are no errors displayed.  If there are go back and check the settings.

View the help document to learn how to analyze data sets

http://<sbeams-server>/doc/Microarray/affy_help_pages/isb_help.php?help_page=Analysis/Pipeline/Pipeline_overview.xml
Read about, "Grouping arrays","Normalizing Array Data" and "Analyze Arrays"


-------------------------------------------------------------------------------
Troubleshooting

1) How to re-generate and update table schemas

- Drop table and (firstly) its constraints, via SQL commands. Look under 
  DOMAIN_DROPCONSTRAINTS.mssql and DOMAIN_DROPTABLES.mssql.
  e.g. look under Core_DROPCONSTRAINTS.mssql and Core_DROPTABLES.mssql

- Edit the appropriate $DOMAIN_table_column.txt file
  e.g. make a field in conf/Core/Core_table_property.txt nullable=N

- Generate new schema files using generate_schema.pl
  e.g.  cd $SBEAMS/lib/scripts/Core
	./generate_schema.pl \
          --table_prop ../../conf/Core/Core_table_property.txt \
          --table_col ../../conf/Core/Core_table_column.txt \
          --schema_file ../../sql/Core/Core \
          --destination_type mssql

- Now re-create table and its constraints using the new (updated) ll.
  e.g. look under Core_CREATETABLES.mssql and Core_CREATECONSTRAINTS.mssql

- Populate the table, if required.
  e.g. look in Core_POPULATE.mssql

-------------------------------------------------------------------------------
2) 
